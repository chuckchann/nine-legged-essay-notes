# blotdb

------

## 1. ç®€ä»‹

**boltdbæ˜¯ä¸€ä¸ªçº¯goç¼–å†™çš„æ”¯æŒäº‹åŠ¡çš„æ–‡ä»¶å‹å•æœºkvæ•°æ®åº“ã€‚** å…¶å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

- å•æœºéƒ¨ç½²ï¼šä¸éœ€è¦è€ƒè™‘**CAP**
- æ”¯æŒäº‹ç‰©ï¼šä»…å…è®¸**å¤šä¸ªåªè¯»äº‹åŠ¡å’Œæœ€å¤šä¸€ä¸ªè¯»å†™äº‹åŠ¡**åŒæ—¶è¿è¡Œ
- ç´¢å¼•ç»“æ„ï¼šå› ä¸ºæ˜¯kvå‹çš„æ•°æ®åº“ï¼Œæ‰€ä»¥å¤©ç„¶åœ°åªæœ‰ä¸»é”®ç´¢å¼•ï¼ˆ**B+æ ‘å®ç°**ï¼‰ï¼Œå‡å°‘äº†ç£ç›˜IO
- ç¼“å­˜ç®¡ç†ï¼šä»…ç®¡ç†å†™ç¼“å­˜ï¼Œåˆ©ç”¨**mmap**ç®¡ç†è¯»ç¼“å­˜

------

## 2. æ ¸å¿ƒæ•°æ®ç»“æ„åˆ†æ

å…ˆä»ä»‹ç»ä¸€ä¸‹boltä½¿ç”¨çš„ä¸€äº›åº•å±‚çš„æ•°æ®ç»“æ„ã€‚

- db
- page
- node
- bucket
- cursor

### <u>*1. db*</u>

åœ¨boltdbä¸­ï¼Œå®ƒçš„æ•°æ®å…¨éƒ¨éƒ½æ˜¯å­˜å‚¨åœ¨æ–‡ä»¶ä¸Šï¼Œä¸€ä¸ªdbå¯¹åº”ä¸€ä¸ªçœŸå®çš„ç£ç›˜æ–‡ä»¶ã€‚

```go
func main()  {
	db, err := bolt.Open("my.db", 0600, nil)
	if err != nil {
		log.Fatal(err)
	}
	defer db.Close()
}
```

æ‰§è¡Œå®Œä¸Šé¢çš„ä»£ç åï¼Œå¯ä»¥çœ‹åˆ°æ ¹ç›®å½•å¤šä¸€ä¸ªmy.dbçš„æ–‡ä»¶

```shell
ll

total 40
-rw-r--r--  1 chuckchen  staff   173B Nov 16 10:56 main.go
-rw-------  1 chuckchen  staff    16K Nov 16 10:57 my.db

```

### <u>*2. page*</u>

åœ¨å…·ä½“çš„ç£ç›˜æ–‡ä»¶ä¸­ï¼Œboltdbåˆæ˜¯ä»¥pageä¸ºå•ä½æ¥è¯»å–å’Œå†™å…¥æ•°æ®åº“çš„ï¼Œå³æ•°æ®åœ¨ç£ç›˜ä¸Šæ˜¯ä»¥pageä¸ºå•ä½è¿›è¡Œå­˜å‚¨çš„ï¼Œpageçš„å¤§å°ä¸æ“ä½œç³»ç»Ÿä¿æŒä¸€è‡´ï¼ˆä¸€èˆ¬ä¸º4kï¼‰ã€‚

å…¶ä¸­æ¯ä¸ªpageåˆç”± **é¡µå¤´æ•°æ®** + **çœŸå®æ•°æ®** ç»„æˆï¼Œé¡µçš„æ•°æ®ç»“æ„å¦‚ä¸‹ï¼š

![storage-and-cache-page-layout](image/storage-and-cache-page-layout.jpg)

pageçš„æ•°æ®å®šä¹‰å¦‚ä¸‹ï¼š

```go
//page.go

type pgid uint64

type page struct {
  //page header 
	id       pgid    //é¡µid
	flags    uint16  //æ ‡è®°ä½ï¼Œç”¨æ¥è¡¨ç¤ºé¡µçš„ç±»å‹ï¼Œæšä¸¾ä¸‹é¢å†ä»‹ç»
	count    uint16  //ä¸ªæ•°ï¼Œç”¨æ¥è®°å½•pageä¸­å…ƒç´ çš„ä¸ªæ•°
	overflow uint32  //å½“é‡åˆ°ä½“ç§¯å·¨å¤§ï¼Œå•ä¸ªpageæ— æ³•è£…ä¸‹çš„æ•°æ®æ—¶ï¼Œä¼šæº¢å‡ºåˆ°å…¶ä»–paageï¼Œoverflowè®°å½•æº¢å‡ºæ€»æ•°
  
  //page body
	ptr      uintptr //æŒ‡å‘pageæ•°æ®çš„å†…å­˜åœ°å€ï¼Œè¯¥å­—æ®µä»…åœ¨å†…å­˜ä¸­å­˜åœ¨
}
```

pageç±»å‹çš„æšä¸¾å€¼å¦‚ä¸‹ï¼š

```go
//page.go

const (
  branchPageFlag   = 0x01  //åˆ†æ”¯èŠ‚ç‚¹é¡µ å­˜å‚¨ç´¢å¼•ä¿¡æ¯(é¡µå·ã€å…ƒç´ keyå€¼)ï¼Œå³B+æ ‘çš„éå¶å­èŠ‚ç‚¹
  leafPageFlag     = 0x02  //å¶å­èŠ‚ç‚¹é¡µ å­˜å‚¨æ•°æ®ä¿¡æ¯(é¡µå·ï¼Œkvå€¼)ï¼Œå³B+æ ‘çš„
  metaPageFlag     = 0x04  //å­˜å‚¨æ•°æ®åº“çš„å…ƒä¿¡æ¯(ç©ºé—²åˆ—è¡¨é¡µidã€æ”¾ç½®æ¡¶çš„æ ¹é¡µç­‰)
	freelistPageFlag = 0x10  //å­˜å‚¨å“ªäº›é¡µæ˜¯ç©ºé—²é¡µï¼Œå¯ä»¥ç”¨æ¥åç»­åˆ†é…ç©ºé—´æ—¶ï¼Œä¼˜å…ˆè€ƒè™‘åˆ†é…
)
```

ä¸‹é¢å†å…·ä½“çœ‹çœ‹æ¯ç§pageç±»å‹åˆ†åˆ«æœ‰ä»€ä¹ˆä½œç”¨ã€‚

#### <u>*2.1. meta*</u>

meta page è®°å½• Bolt å®ä¾‹çš„æ‰€æœ‰å…ƒæ•°æ®ï¼Œå®ƒå‘Šè¯‰ç”¨æˆ·**è¿™æ˜¯ä»€ä¹ˆæ–‡ä»¶**ä»¥åŠ**å¦‚ä½•è§£è¯»è¿™ä¸ªæ–‡ä»¶**ï¼Œå…·ä½“ç»“æ„å¦‚ä¸‹ï¼š

![storage-and-cache-meta-page-layout](image/storage-and-cache-meta-page-layout.jpg)

```go
//db.go

type meta struct {
	magic    uint32 //éšæœºæ•°ï¼Œç”¨æ¥ç¡®å®šè¯¥æ–‡ä»¶æ˜¯ä¸€ä¸ªboltæ•°æ®åº“æ–‡ä»¶(å¦ä¸€ç§æ–‡ä»¶èµ·å§‹ä½ç½®æ‹¥æœ‰ç›¸åŒæ•°æ®çš„å¯èƒ½æ€§æä½)
	version  uint32 //è¡¨æ˜è¯¥æ–‡ä»¶æ‰€å±çš„boltç‰ˆæœ¬ï¼Œä¾¿äºæ—¥ååšå…¼å®¹ä¸è¿ç§»
	pageSize uint32 //é¡µå¤§å° ä¸æ“ä½œç³»ç»Ÿä¸€è‡´
	flags    uint32 //ä¿ç•™å­—æ®µï¼Œæœªä½¿ç”¨
	root     bucket //boltå®ä¾‹æ‰€æœ‰ç´¢å¼•å’ŒåŸæ•°æ®è¢«ç»„ç»‡æˆä¸€ä¸ªæ ‘å½¢ç»“æ„ï¼Œroot å°±æ˜¯æ ¹èŠ‚ç‚¹
	freelist pgid   //boltåˆ é™¤æ•°æ®æ—¶å¯èƒ½å‡ºç°å¯Œä½™çš„ç©ºé—´ï¼Œè¿™äº›ç©ºé—´ä¼šè¢«è®°å½•åœ¨freelistä¸­å¤‡ç”¨
	pgid     pgid   //ä¸‹ä¸€ä¸ªè¦è¢«åˆ†é…çš„ page çš„ idï¼Œå–å€¼å¤§äºå·²åˆ†é…çš„æ‰€æœ‰ pages çš„ id
	txid     txid   //ä¸‹ä¸€ä¸ªè¦è¢«åˆ†é…çš„äº‹åŠ¡ idã€‚äº‹åŠ¡ id å•è°ƒé€’å¢ï¼Œå¯ä»¥è¢«ç†è§£ä¸ºäº‹åŠ¡æ‰§è¡Œçš„é€»è¾‘æ—¶é—´
	checksum uint64 //ç”¨äºç¡®è®¤ meta page æ•°æ®æœ¬èº«çš„å®Œæ•´æ€§ï¼Œä¿è¯è¯»å–çš„æ˜¯ä¸Šä¸€æ¬¡å†™å…¥çš„æ•°æ®
}
```

å°†metaå†™å…¥pageä»£ç å¦‚ä¸‹ï¼š

```go
func (m *meta) write(p *page) {
	if m.root.root >= m.pgid {
		panic(fmt.Sprintf("root bucket pgid (%d) above high water mark (%d)", m.root.root, m.pgid))
	} else if m.freelist >= m.pgid {
		panic(fmt.Sprintf("freelist pgid (%d) above high water mark (%d)", m.freelist, m.pgid))
	}

  //page id è¦ä¹ˆæ˜¯0ï¼Œè¦ä¹ˆæ˜¯1  è¿™å–å†³äº meta.txid
	p.id = pgid(m.txid % 2)
	//è®¾ç½®pageç±»å‹
  p.flags |= metaPageFlag

	// è®¡ç®—checksum
	m.checksum = m.sum64()

  //å°†metæ‹·è´åˆ°page.ptr
	m.copy(p.meta())
}
```

#### <u>*2.2 freelist*</u>

freelist è®°å½•ç€ä¸€ä¸ª**æœ‰åº**çš„ page id åˆ—è¡¨ï¼š

![storage-and-cache-freelist-page-layout](image/storage-and-cache-freelist-page-layout.jpg)

freelistçš„æ•°æ®ç»“æ„å¦‚ä¸‹ï¼š

```go
//freelist.go

type freelist struct {
	ids     []pgid          // å¯ä»¥ç”¨æ¥åˆ†é…çš„ç©ºé—²é¡µid
	pending map[txid][]pgid // å°†æ¥å¾ˆå¿«èƒ½è¢«é‡Šæ”¾çš„ç©ºé—²é¡µï¼Œéƒ¨åˆ†äº‹åŠ¡å¯èƒ½åœ¨è¯»æˆ–åœ¨å†™
	cache   map[pgid]bool   // ä¸€ä¸ªmapï¼Œç”¨æ¥å¿«é€Ÿåˆ¤æ–­æŸä¸ªé¡µæ˜¯å¦ä¸ºç©ºé—²é¡µ
}
```

å°†ç©ºé—²åˆ—è¡¨è½¬æ¢æˆé¡µä¿¡æ¯ï¼Œä»£ç å¦‚ä¸‹ï¼š

```go
// write writes the page ids onto a freelist page. All free and pending ids are
// saved to disk since in the event of a program crash, all pending ids will
// become free.
func (f *freelist) write(p *page) error {
	// Combine the old free pgids and pgids waiting on an open transaction.

	// Update the header flag.
	p.flags |= freelistPageFlag

  //page.countæ˜¯ä¸€ä¸ªuint16ç±»å‹çš„æ•°å­—ï¼Œè¿™ä¹Ÿæ„å‘³ç€å®ƒçš„æœ€å¤§å€¼åªèƒ½åˆ° 2^16 = 65536, å¦‚æœç©ºé—²é¡µçš„ä¸ªæ•°
  //è¶…è¿‡65535ï¼Œåˆ™éœ€è¦å°†page.prtä¸­çš„ç¬¬ä¸€ä¸ªå­—èŠ‚æ¥å­˜å‚¨å…¶ä»–çš„ç©ºé—²é¡µä¸ªæ•°ï¼ŒåŒæ—¶å°†p.countè®¾ç½®ä¸º0xFFFF
	lenids := f.count()   //è®¡ç®—ç©ºé—²åˆ—è¡¨çš„æ€»æ•°
	if lenids == 0 {
		p.count = uint16(lenids)
	} else if lenids < 0xFFFF { // ä¸è¶…è¿‡65535 
		p.count = uint16(lenids)
		f.copyall(((*[maxAllocSize]pgid)(unsafe.Pointer(&p.ptr)))[:])
	} else { //è¶…è¿‡65535
		p.count = 0xFFFF
		((*[maxAllocSize]pgid)(unsafe.Pointer(&p.ptr)))[0] = pgid(lenids)
		f.copyall(((*[maxAllocSize]pgid)(unsafe.Pointer(&p.ptr)))[1:])
	}

	return nil
}
```

todo...

#### <u>*2.3. branch*</u>

bolt åˆ©ç”¨ B+ æ ‘å­˜å‚¨ç´¢å¼•å’Œé”®å€¼æ•°æ®æœ¬èº«ï¼Œè¿™é‡Œçš„ branch æŒ‡çš„å°±æ˜¯ **B+ æ ‘çš„åˆ†æ”¯èŠ‚ç‚¹**ã€‚ branch éœ€è¦å­˜å‚¨å¤§å°ä¸åŒé”®å€¼æ•°æ®ï¼Œå¸ƒå±€å¦‚ä¸‹ï¼š

![storage-and-cache-branch-page-layout](image/storage-and-cache-branch-page-layout.jpg)

åˆ†æ”¯èŠ‚ç‚¹åœ¨å­˜å‚¨æ—¶ï¼Œä¸€ä¸ªåˆ†æ”¯èŠ‚ç‚¹é¡µä¼šå­˜å‚¨å¤šä¸ªåˆ†æ”¯é¡µå…ƒç´ ï¼Œå³branchPageElementï¼Œè¿™ä¸ªä¿¡æ¯å¯ä»¥è®°ä½œä¸ºåˆ†æ”¯é¡µå…ƒç´ å…ƒä¿¡æ¯ã€‚å…ƒä¿¡æ¯ä¸­å®šä¹‰äº†å…·ä½“è¯¥å…ƒç´ çš„é¡µ(pgid)ã€æ”¹å…ƒç´ æ‰€æŒ‡å‘çš„é¡µä¸­

```go
type branchPageElement struct {
	pos   uint32 //è¯¥å…ƒä¿¡æ¯ä¸çœŸå®keyä¹‹é—´çš„åç§»
	ksize uint32 //keyçš„é•¿åº¦
	pgid  pgid //è¯¥å…ƒç´ çš„é¡µid
}
```

Todo...

#### <u>*2.4 leaf*</u>

å¶å­èŠ‚ç‚¹ä¸»è¦ç”¨æ¥å­˜å‚¨å®é™…çš„æ•°æ®ï¼Œleafé‡Œå­˜çš„æ˜¯key + valueï¼Œå…¶å¸ƒå±€å¦‚ä¸‹ï¼š

![storage-and-cache-leaf-page](image/storage-and-cache-leaf-page.jpg)

```go
//page.go

type leafPageElement struct {
	flags uint32 //ç”¨æ¥åˆ¤æ–­æ˜¯å­æ¡¶å¶å­èŠ‚ç‚¹å…ƒç´ è¿˜æ˜¯æ™®é€šçš„k/vå¶å­èŠ‚ç‚¹å…ƒ
	pos   uint32 //åç§»ä½ç½®
	ksize uint32 //keyçš„å¤§å°
	vsize uint32 //valueçš„å¤§å°
}

//å¶å­èŠ‚ç‚¹çš„key
func (n *leafPageElement) key() []byte {
	buf := (*[maxAllocSize]byte)(unsafe.Pointer(n))
  //pos - pos+ksize
	return (*[maxAllocSize]byte)(unsafe.Pointer(&buf[n.pos]))[:n.ksize:n.ksize]
}

//å¶å­èŠ‚ç‚¹çš„value
func (n *leafPageElement) value() []byte {
	buf := (*[maxAllocSize]byte)(unsafe.Pointer(n))
  //pos+ksize - pos+ksize+vsize
	return (*[maxAllocSize]byte)(unsafe.Pointer(&buf[n.pos+n.ksize]))[:n.vsize:n.vsize]
}

//ä»pageé‡Œæå–æŸä¸ªå…·ä½“çš„å¶å­èŠ‚ç‚¹å…ƒç´ 
func (p *page) branchPageElement(index uint16) *branchPageElement {
	return &((*[0x7FFFFFF]branchPageElement)(unsafe.Pointer(&p.ptr)))[index]
}

//ä»pageé‡Œæå–æ‰€æœ‰çš„å¶å­èŠ‚ç‚¹å…ƒç´ 
func (p *page) leafPageElements() []leafPageElement {
	if p.count == 0 {
		return nil
	}
	return ((*[0x7FFFFFF]leafPageElement)(unsafe.Pointer(&p.ptr)))[:]
}
```

### <u>*3. node*</u>

åœ¨**ç£ç›˜**ä¸­æ•°æ®æ˜¯ç”¨**page**æ¥è¡¨ç¤ºçš„ï¼Œä½†æ˜¯åœ¨**å†…å­˜**ä¸­æ•°æ®æ˜¯ç”¨**node**æ¥è¡¨ç¤ºçš„ï¼Œnodeå¯ä»¥è¯´æ˜¯è§£åºåˆ—åŒ–åçš„pageã€‚

```go
//node.go

type node struct {
	bucket     *Bucket //å†…è”çš„bucket ä¸‹é¢ä¼šä»‹ç»
	isLeaf     bool  //åŒºåˆ†æ˜¯åˆ†æ”¯èŠ‚ç‚¹è¿˜æ˜¯å¶å­èŠ‚ç‚¹ 
	unbalanced bool  //å€¼ä¸ºtrueçš„è¯ï¼Œéœ€è¦è€ƒè™‘é¡µåˆå¹¶
	spilled    bool  //å€¼ä¸ºtrueçš„è¯ï¼Œéœ€è¦è€ƒè™‘é¡µåˆ†è£‚
	key        []byte //æœ€å°çš„keyï¼ˆç¬¬ä¸€ä¸ªinodeçš„keyï¼Œinodeæ˜¯æœ‰åºå­˜å‚¨çš„ï¼‰  
	pgid       pgid  //nodeå…³è”çš„ page id
	parent     *node //çˆ¶parent
	children   nodes //å­èŠ‚ç‚¹ å¦‚æœæ˜¯å¶å­èŠ‚ç‚¹è¿™ä¸ªå­—æ®µä¸ºç©º
	inodes     inodes //inodeè¡¨ç¤ºå†…éƒ¨èŠ‚ç‚¹ inodesè¡¨ç¤ºæ”¹èŠ‚ç‚¹å­˜å‚¨çš„è‹¥å¹²ä¸ªkvå€¼ inodeä¼šåœ¨ B+ æ ‘ä¸­è¿›è¡Œè·¯ç”±â€”â€”äºŒåˆ†æŸ¥æ‰¾æ—¶ä½¿ç”¨ã€‚
}


type nodes []*node

func (s nodes) Len() int           { return len(s) }
func (s nodes) Swap(i, j int)      { s[i], s[j] = s[j], s[i] }
func (s nodes) Less(i, j int) bool { return bytes.Compare(s[i].inodes[0].key, s[j].inodes[0].key) == -1 }

//å†…éƒ¨èŠ‚ç‚¹å®šä¹‰
type inode struct {
	flags uint32  // è¡¨ç¤ºæ˜¯å¦æ˜¯å­æ¡¶å¶å­èŠ‚ç‚¹è¿˜æ˜¯æ™®é€šå¶å­èŠ‚ç‚¹ã€‚å¦‚æœflagså€¼ä¸º1è¡¨ç¤ºå­æ¡¶å¶å­èŠ‚ç‚¹ï¼Œå¦åˆ™ä¸ºæ™®é€šå¶å­èŠ‚ç‚¹
	pgid  pgid  //å½“inodeä¸ºåˆ†æ”¯å…ƒç´ æ—¶ï¼Œpgidæ‰æœ‰å€¼ï¼Œä¸ºå¶å­å…ƒç´ æ—¶ï¼Œåˆ™æ²¡å€¼
	key   []byte
	value []byte //å½“inodeä¸ºåˆ†æ”¯å…ƒç´ æ—¶ï¼Œvalueä¸ºç©ºï¼Œä¸ºå¶å­å…ƒç´ æ—¶ï¼Œæ‰æœ‰å€¼
}

type inodes []inode

//å°†pageè½¬æ¢ä¸ºå†…å­˜ä¸­çš„node
func (n *node) read(p *page) {
	n.pgid = p.id
	n.isLeaf = ((p.flags & leafPageFlag) != 0)
	n.inodes = make(inodes, int(p.count))

	for i := 0; i < int(p.count); i++ {
		inode := &n.inodes[i]
		if n.isLeaf { //å¦‚æœæ˜¯å¶å­èŠ‚ç‚¹
      //è·å–å¶å­èŠ‚ç‚¹å…ƒç´ 
			elem := p.leafPageElement(uint16(i))
      //å­æ¡¶ or å¶å­èŠ‚ç‚¹
			inode.flags = elem.flags
      //è¯»å–k/v
			inode.key = elem.key()
			inode.value = elem.value()
		} else {//å¦‚æœæ˜¯åˆ†æ”¯èŠ‚ç‚¹
      //è·å–åˆ†æ”¯èŠ‚ç‚¹å…ƒç´ 
			elem := p.branchPageElement(uint16(i))
      //è®°å½•é¡µid
			inode.pgid = elem.pgid
      //è¯»å–k
			inode.key = elem.key()
		}
		_assert(len(inode.key) > 0, "read: zero-length inode key")
	}

	// Save first key so we can find the node in the parent when we spill.
	if len(n.inodes) > 0 {
    //å°†è¯¥é¡µçš„ç¬¬ä¸€ä¸ªkeyæ”¾å…¥node.keyä¸­ï¼Œä»¥ä¾¿çˆ¶èŠ‚ç‚¹ä»¥æ­¤ä½œä¸ºç´¢å¼•è¿›è¡ŒæŸ¥æ‰¾å’Œè·¯ç”±
		n.key = n.inodes[0].key
		_assert(len(n.key) > 0, "read: zero-length node key")
	} else {
		n.key = nil
	}
}

//å°†nodeè½¬æ¢ä¸ºpage
func (n *node) write(p *page) {
	// Initialize page.
  
  //åˆ¤æ–­æ˜¯å¶å­èŠ‚ç‚¹è¿˜æ˜¯åˆ†æ”¯èŠ‚ç‚¹
	if n.isLeaf {
		p.flags |= leafPageFlag
	} else {
		p.flags |= branchPageFlag
	}

	if len(n.inodes) >= 0xFFFF {
		panic(fmt.Sprintf("inode overflow: %d (pgid=%d)", len(n.inodes), p.id))
	}
	p.count = uint16(len(n.inodes))

	// Stop here if there are no items to write.
	if p.count == 0 {
		return
	}

	// Loop over each item and write it to the page.
	b := (*[maxAllocSize]byte)(unsafe.Pointer(&p.ptr))[n.pageElementSize()*len(n.inodes):]
  
  //éå†indoes å°†inodeä¿¡æ¯å†™å…¥page.pträ¸­
	for i, item := range n.inodes {
		_assert(len(item.key) > 0, "write: zero-length inode key")

		// Write the page element.
		if n.isLeaf {
      //æ„å»ºä¸€ä¸ªpageçš„å¶å­èŠ‚ç‚¹å…ƒç´ 
			elem := p.leafPageElement(uint16(i))
      //å°†ç›¸å…³å­—æ®µä¿¡æ¯å†™å…¥å…ƒç´ ä¸­
			elem.pos = uint32(uintptr(unsafe.Pointer(&b[0])) - uintptr(unsafe.Pointer(elem)))
			elem.flags = item.flags
			elem.ksize = uint32(len(item.key))
			elem.vsize = uint32(len(item.value))
		} else {
      //æ„å»ºä¸€ä¸ªpageçš„åˆ†æ”¯èŠ‚ç‚¹å…ƒç´ 
			elem := p.branchPageElement(uint16(i))
      //å°†ç›¸å…³å­—æ®µä¿¡æ¯å†™å…¥å…ƒç´ ä¸­
			elem.pos = uint32(uintptr(unsafe.Pointer(&b[0])) - uintptr(unsafe.Pointer(elem)))
			elem.ksize = uint32(len(item.key))
			elem.pgid = item.pgid
			_assert(elem.pgid != p.id, "write: circular dependency occurred")
		}
    
    //å¦‚æœkvå€¼å¤ªå¤§ è¶…è¿‡äº†å‰©ä¸‹çš„å¯åˆ†é…çš„ç©ºé—´ï¼Œé‚£ä¹ˆéœ€è¦é‡æ–°åˆ†é…ç©ºé—´
		klen, vlen := len(item.key), len(item.value)
		if len(b) < klen+vlen {
			b = (*[maxAllocSize]byte)(unsafe.Pointer(&b[0]))[:]
		}

		//å°†æ•°æ®ï¼ˆkvï¼‰æ”¾åˆ° pageçš„bodyé‡Œ 
		copy(b[0:], item.key)
		b = b[klen:]
		copy(b[0:], item.value)
		b = b[vlen:]
	}

	// DEBUG ONLY: n.dump()
}

//put å†™å…¥kvæ•°æ®
func (n *node) put(oldKey, newKey, value []byte, pgid pgid, flags uint32) {
	if pgid >= n.bucket.tx.meta.pgid {
		panic(fmt.Sprintf("pgid (%d) above high water mark (%d)", pgid, n.bucket.tx.meta.pgid))
	} else if len(oldKey) <= 0 {
		panic("put: zero-length old key")
	} else if len(newKey) <= 0 {
		panic("put: zero-length new key")
	}

	// æŸ¥æ‰¾keyæ‰€åœ¨çš„ä½ç½®
	index := sort.Search(len(n.inodes), func(i int) bool { return bytes.Compare(n.inodes[i].key, oldKey) != -1 })

	// Add capacity and shift nodes if we don't have an exact match and need to insert.
	exact := (len(n.inodes) > 0 && index < len(n.inodes) && bytes.Equal(n.inodes[index].key, oldKey))
	if !exact {
    //keyå¦‚æœä¸å­˜åœ¨å°±æ’å…¥
		n.inodes = append(n.inodes, inode{})
		copy(n.inodes[index+1:], n.inodes[index:])
	}

  //ä¿®æ”¹(æ–°å¢) keyå¯¹åº”çš„valueå€¼
	inode := &n.inodes[index]
	inode.flags = flags
	inode.key = newKey
	inode.value = value
	inode.pgid = pgid
	_assert(len(inode.key) > 0, "put: zero-length inode key")
}

//nodeçš„åˆ†è£‚ä¸åˆå¹¶ã€‚ã€‚ã€‚todo


```

### <u>*4. bucket*</u>

bucketæ˜¯ä¸€å †kvå¯¹çš„é›†åˆï¼Œå¦‚æœ**db**ä»£è¡¨å…³ç³»å‹æ•°æ®åº“ä¸­çš„**"åº“"**ï¼Œé‚£ä¹ˆ**bucket**åˆ™ä»£è¡¨å…³ç³»å‹æ•°æ®åº“ä¸­çš„**"è¡¨"**ã€‚bucketè¿˜æ”¯æŒæ— é™åµŒå¥—ï¼Œå³bucketé‡Œå¯ä»¥åˆ›å»ºå­bucketï¼Œä¸ºå¼€å‘è€…å½’ç±»æ•°æ®æä¾›æ›´çµæ´»çš„æ–¹æ¡ˆã€‚**ä¸€ä¸ªbucketä»£è¡¨ä¸€é¢—å®Œæ•´çš„ b+æ ‘**ã€‚

```go
//bucket.go

type Bucket struct {
	*bucket                     // å†…è”çš„bucket ä¸‹é¢ä¼šä»‹ç»åˆ°
	tx       *Tx                // å…³è”çš„äº‹ç‰© äº‹åŠ¡åé¢å†è®² å…ˆå¿½ç•¥
	buckets  map[string]*Bucket // å½“å‰æ¡¶çš„å­æ¡¶
	page     *page              // å†…è”æ¨¡å¼ä¸‹ æŒ‡å†…è”pageçš„æŒ‡é’ˆ
	rootNode *node              // æ ¹æ¡¶é¡µå¯¹åº”çš„node
	nodes    map[pgid]*node     // åœ¨è¿™ä¸ªbucketä¸‹ åœ¨å†…å­˜ä¸­çš„node

	// Sets the threshold for filling nodes when they split. By default,
	// the bucket will fill to 50% but it can be useful to increase this
	// amount if you know that your write workloads are mostly append-only.
	//
	// This is non-persisted across transactions so it must be set in every Tx.
  
  //å¡«å……ç‡
	FillPercent float64
}

type bucket struct {
	root     pgid   // æ ¹æ¡¶ï¼ˆğŸ‘‡ä¼šè§£é‡Šä»€ä¹ˆæ˜¯æ ¹æ¡¶ï¼‰çš„page id 
	sequence uint64 // å•è°ƒé€’å¢çš„åºåˆ—å·
}
```

åœ¨åˆå§‹åŒ–æ–°çš„å®ä¾‹æ—¶boltä¼šåˆ›å»ºä¸€ä¸ªpage (pgid=3) æ¥å­˜å‚¨**æ ¹æ¡¶**ï¼Œæ ¹æ¡¶æŒ‡å‘ä¸€ä¸ªç©ºçš„ leaf pageï¼Œè¿™ä¸ª leaf page å°†æˆä¸ºæ‰€æœ‰ç”¨æˆ·åˆ›å»ºçš„å­æ¡¶åŠkvæ•°æ®çš„å®¹å™¨ï¼Œåœ¨db.init()ä¸­å¯ä»¥çœ‹åˆ°åˆ›å»ºpgid = 3 çš„è¿‡ç¨‹ã€‚

```GO
func (db *DB) init() error {
	//
  ...
	// Create two meta pages on a buffer.
  ...

	// Write an empty freelist at page 3.
  ...

	// pgid = 3 çš„è¿™ä¸€é¡µç”¨æ¥å­˜æ”¾root nod
	p = db.pageInBuffer(buf[:], pgid(3))
	p.id = pgid(3)
	p.flags = leafPageFlag
	p.count = 0

	// Write the buffer to our data file.
  ...

	return nil
}
```

åœ¨æ­£å¸¸çš„æƒ…å†µä¸‹ï¼Œæ¯ä¸€ä¸ªbucketéƒ½æœ‰è‡ªå·±ç‹¬ç«‹çš„pageæ¥æ„é€ è‡ªå·±çš„ä¸€é¢— b+ æ ‘ï¼Œä½†æ˜¯å½“ä¸€ä¸ªdbå†…çš„bucketéå¸¸å¤šï¼Œä½†æ˜¯æ¯ä¸ªbucketçš„æ•°æ®é‡éƒ½éå¸¸å°çš„æ—¶å€™ï¼Œå°±ä¼šäº§ç”Ÿå†…éƒ¨ç¢ç‰‡ï¼Œæµªè´¹å­˜å‚¨ç©ºé—´ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œboltdbé‡‡ç”¨**inline-bucket**çš„æ¨¡å¼ã€‚inline-bucketæ¡¶ä¸ä¼šå ç”¨å•ç‹¬çš„pageï¼Œè€Œæ˜¯**å°†bucketçš„æ•°æ®æ”¾inline-pageé‡Œé¢**ï¼Œæ¯ä¸ªinline-pageæ™®é€šçš„pageä¸€æ ·æœ‰ page headerã€element headersã€dataï¼Œä½†åœ¨å­˜å‚¨æ—¶å®ƒå°†è¢«åºåˆ—åŒ–æˆä¸€èˆ¬çš„äºŒè¿›åˆ¶æ•°æ®ä¸æ¡¶åä¸€èµ·ä½œä¸ºæ™®é€šé”®å€¼æ•°æ®å‚¨å­˜ã€‚

åˆå§‹åŒ–å®Œæˆåå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![bucket-root-bucket](image/bucket-root-bucket.jpg)

åˆå§‹åŒ–å®Œæˆååˆ›å»ºä¸€ä¸ªåå«â€œb1â€çš„æ¡¶ï¼Œæ­¤æ—¶æ¡¶ä¸­çš„æ•°æ®é‡è¿˜å¤ªå°ï¼Œæ‰€ä»¥åˆ›å»ºçš„æ˜¯inline-bucketï¼Œåˆ›å»ºå®Œæ¡¶åå¦‚å›¾æ‰€ç¤ºï¼š

![bucket-new-bucket-b1](image/bucket-new-bucket-b1.jpg)

å¾€b1æ¡¶é‡Œæ’å…¥{k1, v1}ï¼Œå®Œæˆåå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![bucket-insert-new-inline-bucket](image/bucket-insert-new-inline-bucket.jpg)

å½“b1æ¡¶ä¸­çš„æ•°æ®åˆ°ä¸€å®šé‡ï¼Œè¶…è¿‡ inline-bucket å¤§å°æ—¶ï¼Œinline-bucket å°±ä¼šè½¬åŒ–æˆæ­£å¸¸çš„bucketï¼Œå¹¶ä¸”èƒ½å¤Ÿåˆ†é…åˆ°å±äºè‡ªå·±çš„pageã€‚

![bucket-normal-bucket](image/bucket-normal-bucket.jpg)

æ’å…¥æ›´å¤šçš„é”®å€¼æ•°æ®ï¼Œb1 æ¡¶å°±ä¼šé•¿æˆä¸€æ£µæ›´èŒ‚ç››çš„ B+ æ ‘ï¼š

![bucket-normal-bucket-b-plus-tree](image/bucket-normal-bucket-b-plus-tree.jpg)

å¦‚æœä½¿ç”¨è€…åœ¨åŒä¸€ä¸ªdbé‡Œåˆ›å»ºæ›´å¤šåƒb1ä¸€æ ·çš„bucketï¼Œç›´åˆ°ä¸€ä¸ª leaf page æ— æ³•å®¹çº³æ ¹æ¡¶çš„æ‰€æœ‰å­èŠ‚ç‚¹ï¼Œè¿™æ—¶ root bucket è‡ªèº«ä¹Ÿå°†é•¿æˆä¸€æ£µæ›´èŒ‚ç››çš„ b+ æ ‘ï¼š

![bucket-root-bucket-tree](image/bucket-root-bucket-tree.jpg)

### <u>*5. cursor*</u>

å‰é¢è¯´åˆ°bucketæ˜¯ä¸€é¢—b+æ ‘ï¼Œç”¨æ¥å­˜å‚¨dbæ•°æ®ï¼Œé‚£ä¹ˆå°±å¿…å®šéœ€è¦å¯¹è¿™é¢—äºŒå‰æ ‘è¿›è¡Œå¢åˆ æ”¹æŸ¥ã€‚cursorå³ä¸‹æ ‡ï¼Œcursorçš„ä½œç”¨æ˜¯**åœ¨bucketä¸Šæ‰¾åˆ°å¯¹åº”çš„æ•°æ®**ï¼Œç„¶åå†è¿›è¡Œæ“ä½œã€‚ç®€è€Œè¨€ä¹‹å¯¹bucketè¿™é¢—b+æ ‘ä¸Šçš„éå†/æŸ¥æ‰¾åŠŸèƒ½ç”±cursoræ¥å®Œæˆã€‚

ä¸‹é¢ä»£ç çš„åŠŸèƒ½æ˜¯åˆ›å»º ä¸€ä¸ªä¸è¿™ä¸ªbucketç›¸å…³çš„cursorã€‚

```go
//bucket.go

//åˆ›å»ºçš„cursoråªåœ¨äº‹åŠ¡èŒƒå›´ä¹‹å†…æœ‰æ•ˆ
//äº‹åŠ¡ç»“æŸåä¸è¦å†ä½¿ç”¨è¿™ä¸ªcursor
func (b *Bucket) Cursor() *Cursor {
	// Update transaction statistics.
	b.tx.stats.CursorCount++

	// Allocate and return a cursor.
	return &Cursor{
		bucket: b,
		stack:  make([]elemRef, 0),
	}
}
```

 cursorçš„æ•°æ®ç»“æ„åŠä¸€äº›æ–¹æ³•å¦‚ä¸‹æ‰€ç¤ºï¼š

```go
//cursor.go

type Cursor struct {
	bucket *Bucket   //å¯¹åº”çš„bucket
  
  //åœ¨cursorçš„ä½¿ç”¨è¿‡ç¨‹ä¸­ï¼Œé€šå¸¸ä¸ä¼šä¸€æ¬¡æ€§éå†å®Œæ‰€æœ‰æ•°æ®ï¼Œè€Œæ˜¯ç”¨
  //stackè¿™ä¸ªå­—æ®µæ¥è®°å½•æ‰€æŸ¥è¯¢è¿‡ç¨‹ä¸­ç»å†çš„è·¯å¾„ï¼ˆä¹Ÿå¯ä»¥ç†è§£ä¸ºæœç´¢çš„è·¯å¾„ï¼‰
  //ä»¥æ–¹ä¾¿cursorè®°å½•ä¸Šä¸€æ¬¡æ‰€åœ¨çš„ä½ç½®ä¿¡æ¯
	stack  []elemRef 
}

//å…ƒç´ å¼•ç”¨
type elemRef struct {
	page  *page
	node  *node
	index int
}

//åˆ¤æ–­æ˜¯å¦ä¸ºå¶å­èŠ‚ç‚¹
func (r *elemRef) isLeaf() bool {
	if r.node != nil {
		return r.node.isLeaf
	}
	return (r.page.flags & leafPageFlag) != 0
}

//å…ƒç´ ä¸ªæ•°
func (r *elemRef) count() int {
	if r.node != nil {
		return len(r.node.inodes)
	}
	return int(r.page.count)
}
```

é’ˆå¯¹ä¸€é¢—b+æ ‘ï¼Œcursoræä¾›äº†ä¸¤ç§ç±»å‹çš„æ–¹æ³•ï¼š

1. é¡ºåºè®¿é—®/éå†ï¼šFirstã€Lastã€Nextã€Prev
2. éšæœºè®¿é—®/æ£€ç´¢ï¼šSeek

```go
//æ ¹æ®keyè¿”å›å¯¹åº”çš„kvå€¼
func (c *Cursor) Seek(seek []byte) (key []byte, value []byte) {
  //æŸ¥æ‰¾å¯¹åº”çš„kv flagsä»£è¡¨æ˜¯åµŒå¥—å­æ¡¶è¿˜æ˜¯æ™®é€škv
	k, v, flags := c.seek(seek)

	// If we ended up after the last element of a page then move to the next one.
	if ref := &c.stack[len(c.stack)-1]; ref.index >= ref.count() {
		k, v, flags = c.next()
	}

	if k == nil { //å¯¹åº”çš„keyä¸å­˜åœ¨
		return nil, nil
	} else if (flags & uint32(bucketLeafFlag)) != 0 { //keyå­˜å‚¨çš„æ˜¯åµŒå¥—çš„å­æ¡¶ æ‰€ä»¥è¿”å›çš„valueæ˜¯nil
		return k, nil
	}
	return k, v
}

//å†…éƒ¨çš„seekæ–¹æ³•
func (c *Cursor) seek(seek []byte) (key []byte, value []byte, flags uint32) {
	_assert(c.bucket.tx.db != nil, "tx closed")

	// Start from root page/node and traverse to correct page.
	c.stack = c.stack[:0]
	c.search(seek, c.bucket.root)
	ref := &c.stack[len(c.stack)-1]

	// æ²¡æ‰¾åˆ°
	if ref.index >= ref.count() {
		return nil, nil, 0
	}

	// If this is a bucket then return a nil value.
	return c.keyValue()
}

//å†…éƒ¨çš„searchæ–¹æ³• ä½¿ç”¨é€’å½’äºŒåˆ†æŸ¥æ‰¾å¯¹åº”çš„key è¿™æ˜¯seekä¸­æœ€æ ¸å¿ƒçš„æ–¹æ³•
func (c *Cursor) search(key []byte, pgid pgid) {
  
  //è·å–pgidå¯¹åº”çš„ node æˆ–è€… page
	p, n := c.bucket.pageNode(pgid)
	if p != nil && (p.flags&(branchPageFlag|leafPageFlag)) == 0 {
		panic(fmt.Sprintf("invalid page type: %d: %x", p.id, p.flags))
	}
  //è®°å½•è·¯å¾„ æ”¾åˆ°stacké‡Œ
	e := elemRef{page: p, node: n}
	c.stack = append(c.stack, e)

	// å¦‚æœå·²ç»æ˜¯b+æ ‘å¶å­èŠ‚ç‚¹äº†  
	if e.isLeaf() {
    //
		c.nsearch(key)
    //ç»“æŸé€’å½’
		return
	}

  //åœ¨éå†è¿‡ç¨‹ä¸­ æœ‰å¯èƒ½éå†åˆ°çš„å½“å‰åˆ†æ”¯èŠ‚ç‚¹æ•°æ®å¹¶æ²¡æœ‰åœ¨å†…å­˜ä¸­ï¼Œæ­¤æ—¶å°±éœ€è¦ä»pageä¸­åŠ è½½æ•°æ®éå†ã€‚æ‰€ä»¥åœ¨éå†è¿‡ç¨‹ä¸­ï¼Œä¼˜å…ˆåœ¨nodeä¸­æ‰¾ï¼Œå¦‚æœnodeä¸ºç©ºçš„æ—¶å€™æ‰ä¼šé‡‡ç”¨pageæ¥æŸ¥æ‰¾
	if n != nil {
		c.searchNode(key, n)
		return
	}
	c.searchPage(key, p)
}

//pageNode æŸ¥æ‰¾pgidå¯¹åº”çš„åœ¨å†…å­˜ä¸­çš„node æˆ–è€… æ˜¯åº•å±‚çš„page
func (b *Bucket) pageNode(id pgid) (*page, *node) {
	// Inline buckets have a fake page embedded in their value so treat them
	// differently. We'll return the rootNode (if available) or the fake page.
	if b.root == 0 { //b.root == 0 ä»£è¡¨å†…è”æ¨¡å¼
		if id != 0 {
			panic(fmt.Sprintf("inline bucket non-zero page access(2): %d != 0", id))
		}
		if b.rootNode != nil {
			return nil, b.rootNode
		}
		return b.page, nil
	}

	// ä»è¿™ä¸ªbucketå­˜åœ¨å†…å­˜ä¸­çš„nodeä¸­æŸ¥æ‰¾
	if b.nodes != nil {
		if n := b.nodes[id]; n != nil {
			return nil, n
		}
	}

	// æœ€åä»äº‹åŠ¡é‡ŒæŸ¥æ‰¾ã€‚ã€‚ã€‚ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ
	return b.tx.page(id), nil
}

// searchNode åœ¨nodeé‡ŒæŸ¥æ‰¾å…·ä½“çš„key
func (c *Cursor) searchNode(key []byte, n *node) {
	var exact bool
	index := sort.Search(len(n.inodes), func(i int) bool {
		// TODO(benbjohnson): Optimize this range search. It's a bit hacky right now.
		// sort.Search() finds the lowest index where f() != -1 but we need the highest index.
		ret := bytes.Compare(n.inodes[i].key, key)
		if ret == 0 {
			exact = true
		}
		return ret != -1
	})
	if !exact && index > 0 {
		index--
	}
	c.stack[len(c.stack)-1].index = index

	// é€’å½’æŸ¥æ‰¾ä¸‹ä¸€é¡µ
	c.search(key, n.inodes[index].pgid)
}

// searchPage åœ¨pageé‡ŒæŸ¥æ‰¾å…·ä½“çš„key
func (c *Cursor) searchPage(key []byte, p *page) {
	// äºŒåˆ†æŸ¥æ‰¾æ‰€æœ‰çš„elements
	inodes := p.branchPageElements()

	var exact bool
	index := sort.Search(int(p.count), func(i int) bool {
		// TODO(benbjohnson): Optimize this range search. It's a bit hacky right now.
		// sort.Search() finds the lowest index where f() != -1 but we need the highest index.
		ret := bytes.Compare(inodes[i].key(), key)
		if ret == 0 {
			exact = true
		}
		return ret != -1
	})
	if !exact && index > 0 {
		index--
	}
	c.stack[len(c.stack)-1].index = index

	// é€’å½’æŸ¥æ‰¾ä¸‹ä¸€é¡µ
	c.search(key, inodes[index].pgid)
}


// nsearch åœ¨å¶å­èŠ‚ç‚¹ï¼ˆstackçš„æ ˆé¡¶ï¼‰æŸ¥æ‰¾å¯¹åº”çš„key 
func (c *Cursor) nsearch(key []byte) {
  //ä»æ ˆé¡¶è·å–å¶å­èŠ‚ç‚¹å¯¹åº”çš„ page node
	e := &c.stack[len(c.stack)-1]
	p, n := e.page, e.node

	// å¦‚æœæœ‰node å°±ç›´æ¥ä»nodeä¸­äºŒåˆ†æŸ¥æ‰¾
	if n != nil {
		index := sort.Search(len(n.inodes), func(i int) bool {
			return bytes.Compare(n.inodes[i].key, key) != -1
		})
		e.index = index //æ ‡è®°ç´¢å¼•ä½ç½®
		return
	}

	// ä»pageä¸­äºŒåˆ†æŸ¥æ‰¾
	inodes := p.leafPageElements()
	index := sort.Search(int(p.count), func(i int) bool {
		return bytes.Compare(inodes[i].key(), key) != -1
	})
	e.index = index //æ ‡è®°ç´¢å¼•ä½ç½®
}
```

ä¸Šé¢è®²çš„æ–¹æ³•Seekæ–¹æ³•æ˜¯éšæœºè®¿é—®ï¼Œä¸‹é¢è®²é¡ºåºæŸ¥æ‰¾çš„å‡ ç§æ–¹æ³•ã€‚

First()ç”¨äºæ‰¾åˆ°bucketé‡Œçš„ç¬¬ä¸€ä¸ªæ•°æ®é¡¹ã€‚

```go
func (c *Cursor) First() (key []byte, value []byte) {
	_assert(c.bucket.tx.db != nil, "tx closed")
  
  //æ¸…ç©ºstack
	c.stack = c.stack[:0]
	p, n := c.bucket.pageNode(c.bucket.root)
	c.stack = append(c.stack, elemRef{page: p, node: n, index: 0})
  
  //indexè®¾ä¸º0 å°†cursorç§»åŠ¨è‡³ç¬¬ä¸€ä¸ªå¶å­èŠ‚ç‚¹å¹¶ä¸”index = 0çš„ä½ç½®
	c.first()

	// If we land on an empty page then move to the next value.
	// https://github.com/boltdb/bolt/issues/450
  //......
	if c.stack[len(c.stack)-1].count() == 0 {
		c.next()
	}

  //ä»æ ˆé¡¶çš„refï¼ˆpage æˆ–è€… nodeï¼‰é‡Œè·å–kv
	k, v, flags := c.keyValue()
  //åµŒå¥—å­æ¡¶ or kvå€¼
	if (flags & uint32(bucketLeafFlag)) != 0 {
		return k, nil
	}
	return k, v

}

func (c *Cursor) first() {
	for {
		// Exit when we hit a leaf page.
		var ref = &c.stack[len(c.stack)-1]
		if ref.isLeaf() {
			break //å¶å­èŠ‚ç‚¹ é€€å‡º
		}

		// å½“å‰èŠ‚ç‚¹æ˜¯éå¶å­èŠ‚ç‚¹ ç»§ç»­å¾€ä¸‹ä¸€ä¸ª page æˆ–è€… node æ‰¾
		var pgid pgid
		if ref.node != nil {
			pgid = ref.node.inodes[ref.index].pgid
		} else {
			pgid = ref.page.branchPageElement(uint16(ref.index)).pgid
		}
		p, n := c.bucket.pageNode(pgid)
		c.stack = append(c.stack, elemRef{page: p, node: n, index: 0})
	}
}
```

Last()ç”¨äºæ‰¾åˆ°bucketé‡Œçš„æœ€åä¸€ä¸ªæ•°æ®é¡¹ã€‚

```go
func (c *Cursor) Last() (key []byte, value []byte) {
	_assert(c.bucket.tx.db != nil, "tx closed")
	c.stack = c.stack[:0]
	p, n := c.bucket.pageNode(c.bucket.root)
	ref := elemRef{page: p, node: n}
  
  //index = ref.count()-1
	ref.index = ref.count() - 1
	c.stack = append(c.stack, ref)
	c.last()
	k, v, flags := c.keyValue()
	if (flags & uint32(bucketLeafFlag)) != 0 {
		return k, nil
	}
	return k, v
}

func (c *Cursor) last() {
	for {
		// Exit when we hit a leaf page.
		ref := &c.stack[len(c.stack)-1]
		if ref.isLeaf() {
			break
		}

		// Keep adding pages pointing to the last element in the stack.
		var pgid pgid
		if ref.node != nil {
			pgid = ref.node.inodes[ref.index].pgid
		} else {
			pgid = ref.page.branchPageElement(uint16(ref.index)).pgid
		}
		p, n := c.bucket.pageNode(pgid)

		var nextRef = elemRef{page: p, node: n}
		nextRef.index = nextRef.count() - 1
		c.stack = append(c.stack, nextRef)
	}
}
```

Next() Prev() åˆ†æå®ç°

```go
func (c *Cursor) Next() (key []byte, value []byte) {
    _assert(c.bucket.tx.db != nil, "tx closed")
    k, v, flags := c.next()
    if (flags & uint32(bucketLeafFlag)) != 0 {
        return k, nil
    }
    return k, v
}

//
func (c *Cursor) next() (key []byte, value []byte, flags uint32) {
	for {
    //è¿™é‡Œä»æ ˆé¡¶å¾€æ ˆåº•æ‰¾ å¦‚æœå½“å‰cursorå·²ç»å¤„äºäºŒå‰æ ‘èŠ‚ç‚¹çš„æœ€åä¸€ä¸ªä½ç½®ï¼Œ
    //é‚£ä¹ˆéœ€è¦å›é€€åˆ°éå†è·¯å¾„çš„ä¸Šä¸€ä¸ªèŠ‚ç‚¹ï¼Œç„¶åå†ç»§ç»­æŸ¥æ‰¾ã€‚
		var i int
		for i = len(c.stack) - 1; i >= 0; i-- {
			elem := &c.stack[i]
			if elem.index < elem.count()-1 {
        //æ‰¾ä¸‹ä¸€ä¸ªä½ç½® 
				elem.index++
				break
			}
		}
    
    //å½“å‰æ¸¸æ ‡å·²ç»åœ¨æœ€åä¸€ä¸ªä½ç½® è¯´æ˜æ²¡æœ‰nextäº†ï¼Œè¿”å› nil
		if i == -1 {
			return nil, nil, 0
		}

    //å»æ‰é‚£äº›å·²ç»å¤„äºæœ«å°¾ä½ç½®çš„èŠ‚ç‚¹
		c.stack = c.stack[:i+1]
    //æ ¹æ®å½“å‰æ ˆçš„ä¿¡æ¯æŸ¥æ‰¾ 
    //å¦‚æœæ˜¯å¶å­èŠ‚ç‚¹ï¼Œfirst()å•¥éƒ½ä¸åšï¼Œç›´æ¥é€€å‡ºã€‚è¿”å›elem.index+1çš„æ•°æ®
    //éå¶å­èŠ‚ç‚¹çš„è¯ï¼Œéœ€è¦ç§»åŠ¨åˆ°stackä¸­æœ€åä¸€ä¸ªè·¯å¾„çš„ç¬¬ä¸€ä¸ªå…ƒç´ 
		c.first()

		// If this is an empty page then restart and move back up the stack.
		// https://github.com/boltdb/bolt/issues/450
		if c.stack[len(c.stack)-1].count() == 0 {
			continue
		}

		return c.keyValue()
	}
}


//
func (c *Cursor) Prev() (key []byte, value []byte) {
	_assert(c.bucket.tx.db != nil, "tx closed")

	// Attempt to move back one element until we're successful.
	// Move up the stack as we hit the beginning of each page in our stack.
	for i := len(c.stack) - 1; i >= 0; i-- {
		elem := &c.stack[i]
		if elem.index > 0 {
      //æŸ¥æ‰¾å‰ä¸€ä¸ªä½ç½®
			elem.index--
			break
		}
		c.stack = c.stack[:i]
	}

	// If we've hit the end then return nil.
	if len(c.stack) == 0 {
		return nil, nil
	}

	// å¦‚æœå½“å‰èŠ‚ç‚¹æ˜¯å¶å­èŠ‚ç‚¹çš„è¯ï¼Œåˆ™ç›´æ¥é€€å‡ºäº†ï¼Œå•¥éƒ½ä¸åšã€‚å¦åˆ™çš„è¯ç§»åŠ¨åˆ°æ–°é¡µçš„æœ€åä¸€ä¸ªèŠ‚ç‚¹
	c.last()
	k, v, flags := c.keyValue()
	if (flags & uint32(bucketLeafFlag)) != 0 {
		return k, nil
	}
	return k, v
}

func (c *Cursor) last() {
	for {
		// Exit when we hit a leaf page.
		ref := &c.stack[len(c.stack)-1]
		if ref.isLeaf() {
			break
		}

		// Keep adding pages pointing to the last element in the stack.
		var pgid pgid
		if ref.node != nil {
			pgid = ref.node.inodes[ref.index].pgid
		} else {
			pgid = ref.page.branchPageElement(uint16(ref.index)).pgid
		}
		p, n := c.bucket.pageNode(pgid)

		var nextRef = elemRef{page: p, node: n}
		nextRef.index = nextRef.count() - 1
		c.stack = append(c.stack, nextRef)
	}
}
```

Delete()  åˆ é™¤æ•°æ®

```go
func (c *Cursor) Delete() error {
	if c.bucket.tx.db == nil {
		return ErrTxClosed
	} else if !c.bucket.Writable() {
		return ErrTxNotWritable
	}

	key, _, flags := c.keyValue()
	// Return an error if current value is a bucket.
	if (flags & bucketLeafFlag) != 0 {
		return ErrIncompatibleValue
	}
  // ä»inodesä¸­ç§»é™¤
	c.node().del(key)

	return nil
}

//ä»inodesä¸­ç§»é™¤	
func (n *node) del(key []byte) {
	// Find index of key.
	index := sort.Search(len(n.inodes), func(i int) bool { return bytes.Compare(n.inodes[i].key, key) != -1 })

	// Exit if the key isn't found.
	if index >= len(n.inodes) || !bytes.Equal(n.inodes[index].key, key) {
		return
	}

	// Delete inode from the node.
	n.inodes = append(n.inodes[:index], n.inodes[index+1:]...)

	// Mark the node as needing rebalancing.
	n.unbalanced = true
}
```

Todo...



## 3. äº‹åŠ¡

boltåªæ”¯æŒä¸¤ç§ç±»å‹çš„äº‹åŠ¡ï¼š**è¯»å†™äº‹åŠ¡**ã€**åªè¯»äº‹åŠ¡**ã€‚åŒä¸€æ—¶åˆ»æœ‰ä¸”åªèƒ½æœ‰ä¸€ä¸ªè¯»å†™äº‹åŠ¡æ‰§è¡Œï¼Œä½†åŒä¸€æ—¶åˆ»å…è®¸å¤šä¸ªåªè¯»äº‹åŠ¡æ‰§è¡Œï¼Œæ¯ä¸ªäº‹åŠ¡éƒ½æ‹¥æœ‰è‡ªå·±çš„ä¸€å¥—ä¸€è‡´æ€§è§†å›¾ã€‚boltå¦‚ä½•æ”¯æŒäº‹åŠ¡çš„ACIDç‰¹æ€§ï¼Ÿ

- **A(åŸå­æ€§)**ï¼šåœ¨boltä¸­ï¼Œæ•°æ®å…ˆå†™å†…å­˜ï¼Œç„¶åå†æäº¤æ—¶åˆ·ç›˜ã€‚å¦‚æœå…¶ä¸­æœ‰å¼‚å¸¸å‘ç”Ÿï¼Œäº‹åŠ¡å°±ä¼šå›æ»šã€‚åŒæ—¶å†åŠ ä¸ŠåŒä¸€æ—¶é—´åªæœ‰ä¸€ä¸ªè¿›è¡Œå¯¹æ•°æ®æ‰§è¡Œå†™å…¥æ“ä½œã€‚æ‰€ä»¥å®ƒè¦ä¹ˆå†™æˆåŠŸæäº¤ã€è¦ä¹ˆå†™å¤±è´¥å›æ»šã€‚ä¹Ÿå°±æ”¯æŒ**åŸå­æ€§**äº†ã€‚  
- **D(æŒä¹…æ€§)**ï¼šboltæ˜¯ä¸€ä¸ªæ–‡ä»¶æ•°æ®åº“ï¼Œæ‰€æœ‰æ•°æ®æœ€ç»ˆéƒ½ä¿å­˜åœ¨æ–‡ä»¶ä¸­ï¼Œå½“äº‹åŠ¡ç»“æŸæ—¶ï¼Œä¼šå¯¹æ•°æ®è¿›è¡Œåˆ·ç›˜ã€‚åŒæ—¶ï¼Œbolté€šè¿‡å†—ä½™ä¸€ä»½å…ƒæ•°æ®æ¥è¿›è¡Œå®¹é”™ã€‚å½“äº‹åŠ¡æäº¤æ—¶ï¼Œå¦‚æœå†™å…¥åˆ°ä¸€åŠæœºå™¨æŒ‚äº†ï¼Œæ­¤æ—¶æ•°æ®å°±ä¼šæœ‰é—®é¢˜ã€‚è€Œå½“boltdbå†æ¬¡æ¢å¤æ—¶ï¼Œä¼šå¯¹å…ƒæ•°æ®è¿›è¡Œæ ¡éªŒå’Œä¿®å¤ã€‚è¿™ä¸¤ç‚¹å°±ä¿è¯äº‹åŠ¡ä¸­çš„**æŒä¹…æ€§**ã€‚
- **I(éš”ç¦»æ€§)**ï¼šboltåœ¨ä¸Šå±‚æ”¯æŒå¤šä¸ªè¿›ç¨‹ä»¥åªè¯»çš„æ–¹å¼æ‰“å¼€æ•°æ®åº“ï¼Œä¸€ä¸ªè¿›ç¨‹ä»¥å†™çš„æ–¹å¼æ‰“å¼€æ•°æ®åº“ã€‚åœ¨æ•°æ®åº“å†…éƒ¨ä¸­äº‹åŠ¡æ”¯æŒä¸¤ç§ï¼Œè¯»å†™äº‹åŠ¡å’Œåªè¯»äº‹åŠ¡ã€‚è¿™ä¸¤ç±»äº‹åŠ¡æ˜¯äº’æ–¥çš„ã€‚åŒä¸€æ—¶é—´å¯ä»¥æœ‰å¤šä¸ªåªè¯»äº‹åŠ¡æ‰§è¡Œï¼Œæˆ–è€…åªèƒ½æœ‰ä¸€ä¸ªè¯»å†™äº‹åŠ¡æ‰§è¡Œï¼Œä¸Šè¿°ä¸¤ç±»äº‹åŠ¡ï¼Œåœ¨åº•å±‚å®ç°æ—¶ï¼Œéƒ½æ˜¯ä¿ç•™ä¸€æ•´å¥—å®Œæ•´çš„è§†å›¾å’Œå…ƒæ•°æ®ä¿¡æ¯ï¼Œå½¼æ­¤ä¹‹é—´ç›¸äº’éš”ç¦»ã€‚å› æ­¤é€šè¿‡è¿™ä¸¤ç‚¹å°±ä¿è¯äº†**éš”ç¦»æ€§**ã€‚
- **C(ä¸€è‡´æ€§)**ï¼š é€šè¿‡å…¶ä»–ä¸‰ä¸ªç‰¹æ€§æ¥å®ç°ã€‚

```go
type Tx struct {
	writable       bool    //åŒºåˆ†æ˜¯è¯»äº‹åŠ¡è¿˜æ˜¯å†™äº‹åŠ¡
	managed        bool    //
	db             *DB     //äº‹åŠ¡æ‰€å±çš„db
	meta           *meta
	root           Bucket
	pages          map[pgid]*page
	stats          TxStats
	commitHandlers []func()  //æäº¤æ—¶æ‰§è¡Œçš„åŠ¨ä½œ

	// WriteFlag specifies the flag for write-related methods like WriteTo().
	// Tx opens the database file with the specified flag to copy the data.
	//
	// By default, the flag is unset, which works well for mostly in-memory
	// workloads. For databases that are much larger than available RAM,
	// set the flag to syscall.O_DIRECT to avoid trashing the page cache.
	WriteFlag int
}

func (tx *Tx) init(db *DB) {
	tx.db = db
	tx.pages = nil

	// æ‹·è´å…ƒä¿¡æ¯
	tx.meta = &meta{}
	db.meta().copy(tx.meta)

	// æ‹·è´è·ŸèŠ‚ç‚¹
	tx.root = newBucket(tx)
	tx.root.bucket = &bucket{}
	*tx.root.bucket = tx.meta.root

	// å¦‚æœæ˜¯å†™äº‹åŠ¡
	if tx.writable {
		tx.pages = make(map[pgid]*page)
		tx.meta.txid += txid(1)
	}
}

//db.go
//å¼€å¯ä¸€ä¸ªäº‹åŠ¡
func (db *DB) Begin(writable bool) (*Tx, error) {
	if writable {
		return db.beginRWTx()
	}
	return db.beginTx()
}

//å¼€å¯è¯»äº‹åŠ¡
func (db *DB) beginTx() (*Tx, error) {
  // è·å–å…ƒä¿¡æ¯é”
	db.metalock.Lock()

	// è·å–mmapé”
	db.mmaplock.RLock()

	// Exit if the database is not open yet.
	if !db.opened {
		db.mmaplock.RUnlock()
		db.metalock.Unlock()
		return nil, ErrDatabaseNotOpen
	}

	// åˆå§‹åŒ–ä¸€ä¸ªäº‹åŠ¡å¯¹è±¡
	t := &Tx{}
	t.init(db)

	// å°†è¿™ä¸ªäº‹åŠ¡æ·»åŠ çš„è¿™ä¸ªdbé‡Œ
	db.txs = append(db.txs, t)
	n := len(db.txs)

	// Unlock the meta pages.
	db.metalock.Unlock()

	// æ›´æ–°äº‹åŠ¡çŠ¶æ€
	db.statlock.Lock()
	db.stats.TxN++
	db.stats.OpenTxN = n
	db.statlock.Unlock()

	return t, nil
}

//å¼€å¯å†™äº‹åŠ¡
func (db *DB) beginRWTx() (*Tx, error) {
	// If the database was opened with Options.ReadOnly, return an error.
	if db.readOnly {
		return nil, ErrDatabaseReadOnly
	}

  // å†™äº‹åŠ¡çš„é” åªæœ‰å½“äº‹åŠ¡ç»“æŸæ—¶æ‰ä¼šé‡Šæ”¾é” è¿™ä¸ªé”ç¡®ä¿äº†ä»»æ„æ—¶åˆ»éƒ½åªèƒ½æœ‰ä¸€ä¸ªå†™äº‹åŠ¡
	db.rwlock.Lock()

	// è·å–å…ƒä¿¡æ¯é” ä»¥ä¿®æ”¹å…ƒä¿¡æ¯é‡Œçš„äº‹åŠ¡æ•°æ®
	db.metalock.Lock()
	defer db.metalock.Unlock()

	// Exit if the database is not open yet.
	if !db.opened {
		db.rwlock.Unlock()
		return nil, ErrDatabaseNotOpen
	}

	// Create a transaction associated with the database.
	t := &Tx{writable: true}
	t.init(db)
	db.rwtx = t

	// æ‰¾åˆ°æœ€å°çš„äº‹åŠ¡id
	var minid txid = 0xFFFFFFFFFFFFFFFF
	for _, t := range db.txs {
		if t.meta.txid < minid {
			minid = t.meta.txid
		}
	}
	if minid > 0 {
    //å°†ä¹‹å‰å…³è”äº‹åŠ¡çš„idå…¨éƒ¨é‡Šæ”¾ï¼Œå› ä¸ºåœ¨åªè¯»äº‹åŠ¡ä¸­ï¼Œæ²¡æ³•é‡Šæ”¾åªè¯»äº‹åŠ¡çš„é¡µï¼ˆå› ä¸ºå¯èƒ½
    //å½“å‰äº‹åŠ¡å·²å®Œæˆï¼Œä½†å…¶ä»–äº‹åŠ¡è¿˜åœ¨ä½¿ç”¨ï¼‰
		db.freelist.release(minid - 1)
	}

	return t, nil
}

//æäº¤äº‹åŠ¡
func (tx *Tx) Commit() error {
	_assert(!tx.managed, "managed tx commit not allowed")
	if tx.db == nil {
		return ErrTxClosed
	} else if !tx.writable {
		return ErrTxNotWritable
	}

	// TODO(benbjohnson): Use vectorized I/O to write out dirty pages.

	// Rebalance nodesã€‚ã€‚ã€‚é‡æ–°å¹³è¡¡nodesã€‚ã€‚
	var startTime = time.Now()
	tx.root.rebalance()
	if tx.stats.Rebalance > 0 {
		tx.stats.RebalanceTime += time.Since(startTime)
	}

	// spill data onto dirty pages.
	startTime = time.Now()
	if err := tx.root.spill(); err != nil {
		tx.rollback()
		return err
	}
	tx.stats.SpillTime += time.Since(startTime)

	// Free the old root bucket.
	tx.meta.root.root = tx.root.root

	opgid := tx.meta.pgid

	// Free the freelist and allocate new pages for it. This will overestimate
	// the size of the freelist but not underestimate the size (which would be bad).
	tx.db.freelist.free(tx.meta.txid, tx.db.page(tx.meta.freelist))
	p, err := tx.allocate((tx.db.freelist.size() / tx.db.pageSize) + 1)
	if err != nil {
		tx.rollback()
		return err
	}
	if err := tx.db.freelist.write(p); err != nil {
		tx.rollback()
		return err
	}
	tx.meta.freelist = p.id

	// If the high water mark has moved up then attempt to grow the database.
	if tx.meta.pgid > opgid {
		if err := tx.db.grow(int(tx.meta.pgid+1) * tx.db.pageSize); err != nil {
			tx.rollback()
			return err
		}
	}

	// Write dirty pages to disk.
	startTime = time.Now()
	if err := tx.write(); err != nil {
		tx.rollback()
		return err
	}

	// If strict mode is enabled then perform a consistency check.
	// Only the first consistency error is reported in the panic.
	if tx.db.StrictMode {
		ch := tx.Check()
		var errs []string
		for {
			err, ok := <-ch
			if !ok {
				break
			}
			errs = append(errs, err.Error())
		}
		if len(errs) > 0 {
			panic("check fail: " + strings.Join(errs, "\n"))
		}
	}

	// Write meta to disk.
	if err := tx.writeMeta(); err != nil {
		tx.rollback()
		return err
	}
	tx.stats.WriteTime += time.Since(startTime)

	// Finalize the transaction.
	tx.close()

	// Execute commit handlers now that the locks have been removed.
	for _, fn := range tx.commitHandlers {
		fn()
	}

	return nil
}
```

Todo ...
